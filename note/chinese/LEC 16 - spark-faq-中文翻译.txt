Spark FAQ

问：Spark目前在任何主要应用程序中使用吗？

答：是的：https://databricks.com/customers

问：博士生创建像Spark规模的项目有多普遍？

答：不常见！这是一个相当大的成就。Matei Zaharia因这项工作获得了ACM博士论文奖。

问：我们应该将Spark视为类似于MapReduce吗？

答：有相似之处，但Spark可以表达难以在MapReduce中高效表达的计算，例如迭代算法。你可以将Spark视为MapReduce的延伸。作者认为Spark足够强大，可以表达一系列先前的计算框架，包括MapReduce（见7.1节）。

有些系统在整合流入的新数据方面比Spark更好，而不是进行批处理。例如，Naiad（https://dl.acm.org/citation.cfm?id=2522738）。Spark也有流支持，虽然它通过"微批处理"上的计算来实现（见Spark Streaming, SOSP 2013）。

还有一些系统允许不同机器之间更细粒度的共享（例如DSM系统）或像Picolo（http://piccolo.news.cs.nyu.edu/）这样的系统，它针对与Spark类似的应用程序。

问：如果RDD允许转换，为什么被称为不可变的？

答：转换产生一个新的RDD，但可能不会被明确物化，因为转换是惰性计算的。在PageRank示例中，每次循环迭代产生一个新的distrib和rank RDD，如相应的血统图所示。

问：分布式系统设计者会担心能源效率吗？

答：能源在CS中是一个大问题！但集群计算中能源效率的重点主要在数据中心的设计以及数据中心内计算机和冷却系统设计上。

芯片设计者非常关注能源；例如，你的处理器动态改变时钟频率以避免处理器过热。

在分布式系统设计中关注能源较少，我认为主要是因为这不是大的收益所在。但也有一些工作，例如见http://www.cs.cmu.edu/~fawnproj/。

问：应用程序如何找出RDD的位置？

答：应用程序在Scala中用变量名命名RDD。每个RDD都有与其关联的位置信息，在其元数据中（见表3）。调度器使用所有这些信息将计算与数据放置在一起。一个RDD可能由多个节点生成，但它是针对RDD的不同分区。

问：Spark如何实现容错？

答：在持久化RDD时，程序员可以指定它必须在几台机器上复制。然而，Spark不需要像Raft这样复杂的协议，因为RDD是不可变的，并且总是可以使用血统图重新计算。

问：为什么Spark使用Scala开发？这种语言有什么特别之处？

答：部分原因是当项目开始时Scala是新的和时髦的。

一个很好的原因是Scala提供了序列化和发送用户定义代码（"闭包"）的能力，如5.2节所讨论的。

这在基于JVM的语言（如Java和Scala）中相当直接，但在C、C++或Go中很难做到，部分原因是共享内存（指针、互斥锁等），部分原因是闭包需要捕获其中引用的所有变量（除非语言运行时可以帮助，否则这很困难）。

问：既然Spark似乎严格更优越，还有人使用MapReduce而不是Spark吗？如果有人使用，为什么？

如果需要的计算很好地符合MapReduce范式，那么使用Spark而不是MapReduce没有优势。

例如，如果计算对大数据集进行单次扫描（map阶段），然后进行聚合（reduce阶段），计算将主要由I/O主导，Spark的内存RDD缓存不会提供好处，因为没有RDD被重用。

Spark在具有大量内部重用的迭代计算方面表现很好，但对于扫描大数据集和聚合的简单作业（即Spark语言中的map()和reduceByKey()转换），在架构上并不比MapReduce或Hadoop有优势。另一方面，Spark在这些计算中也没有理由会慢，所以你真的可以使用任何一个。

问：RDD概念是否在Spark以外的任何系统中实现？

Spark和特定的RDD接口彼此相当紧密地联系在一起。然而，RDD背后的两个关键思想——确定性的、基于血统的重新执行和面向集合的API——肯定在许多系统中广泛使用。例如，DryadLINQ、FlumeJava和Cloud Dataflow提供类似的面向集合的API；论文引用的Dryad和Ciel系统也跟踪数据片段如何计算，并在失败时重新执行该计算，类似于基于血统的容错。

事实上，Spark中的RDD本身现在有些过时了：Spark最近转向了称为"DataFrames"的东西（https://spark.apache.org/docs/latest/sql-programming-guide.html#datasets-and-dataframes），它实现了更面向列的表示，同时保持了RDD的好思想。

问：什么是哈希分区？

哈希分区是来自数据库的概念，用于高效实现数据库连接。使用哈希将RDD分割成分区，意味着对RDD的主键进行哈希，并将所有具有相同哈希的记录存储在同一分区中。如果你有两个具有相同主键的RDD，并且对它们进行哈希分区，那么两个具有相同键的RRD的分区最终将在同一台机器上。如果你需要在这两个RRD上计算join()，这很好，因为join()不需要与其他机器通信，因为具有相同键的分区在同一台机器上。

例如，在PageRank示例中，links和ranks RRD就显示了这一点。它们的键是URL，哈希分区确保两个RRD的"mit.edu"条目最终在同一台机器上。因此，当在"mit.edu"上连接两个RDD时，不需要与其他机器通信。